{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_4xoX__Mce8",
        "colab_type": "text"
      },
      "source": [
        "#Gaussian bayes classifier\n",
        "\n",
        "In this assignment we will use a Gaussian bayes classfier to classify our data points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmrOLukFMW9v",
        "colab_type": "text"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFFLDRpGVu3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import multivariate_normal\n",
        "from sklearn.metrics import classification_report\n",
        "from matplotlib import cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VqZGutNc65m",
        "colab_type": "text"
      },
      "source": [
        "# Load training data\n",
        "\n",
        "Our data has 2D feature $x1, x2$. Data from the two classes is are in $\\texttt{class1_train}$ and $\\texttt{class2_train}$ respectively. Each file has two columns corresponding to the 2D feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyVpK1m7drij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class1_train = pd.read_csv('https://raw.githubusercontent.com/shala2020/shala2020.github.io/master/Lecture_Materials/Assignments/MachineLearning/L3/class1_train').to_numpy()\n",
        "class2_train = pd.read_csv('https://raw.githubusercontent.com/shala2020/shala2020.github.io/master/Lecture_Materials/Assignments/MachineLearning/L3/class2_train').to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV4oAZdlYAwV",
        "colab_type": "text"
      },
      "source": [
        "# Visualize training data\n",
        "Generate 2D scatter plot of the training data. Plot the points from class 1 in red and the points from class 2 in blue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3D3W5XGYCkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBa6Br1-ZF9D",
        "colab_type": "text"
      },
      "source": [
        "# Maximum likelihood estimate of parameters\n",
        "\n",
        "We will model the likelihood, $P(\\mathbf{x}|C_1)$ and $P(\\mathbf{x}|C_2)$ as $\\mathcal{N}(\\mathbf{\\mu_1},|\\Sigma_1)$ and $\\mathcal{N}(\\mathbf{\\mu_2},|\\Sigma_2)$ respectively. The prior probability of the classes are called, $P(C_1)=\\pi_1$ and $P(C_2)=\\pi_2$.\n",
        "\n",
        "The maximum likelihood estimate of the parameters as follows:\n",
        "\\begin{align*}\n",
        "\\pi_k &= \\frac{\\sum_{i=1}^N \\mathbb{1}(t^i=k)}{N}\\\\\n",
        "\\mathbf{\\mu_k} &= \\frac{\\sum_{i=1}^N \\mathbb{1}(t^i=k)\\mathbf{x}^i}{\\sum_{i=1}^N \\mathbb{1}(t^i=k)}\\\\\n",
        "\\Sigma_k &= \\frac{\\sum_{i=1}^N \\mathbb{1}(t^i=k)(\\mathbf{x}^i-\\mathbf{\\mu_k})(\\mathbf{x}^i-\\mathbf{\\mu_k})^T}{\\sum_{i=1}^N \\mathbb{1}(t^i=k)}\\\\\n",
        "\\end{align*}\n",
        "\n",
        "Here, $t^i$ is the target or class of $i^{th}$ sample. $\\mathbb{1}(t^i=k)$ is 1 if $t^i=k$ and 0 otherwise.\n",
        "\n",
        "Compute maximum likelihood values estimates of $\\pi_1$, $\\mu_1$, $\\Sigma_1$ and $\\pi_2$, $\\mu_2$, $\\Sigma_2$ \n",
        "\n",
        "Also print these values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REKlzGnKclHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHshjXHQ8rlb",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the likelihood\n",
        "Now that you have the parameters, let us visualize how the likelihood looks like.\n",
        "\n",
        "1. Use $\\texttt{np.mgrid}$ to generate points uniformly spaced in -5 to 5 along 2 axes\n",
        "1. Use $\\texttt{multivariate_normal.pdf}$ to get compute the Gaussian likelihood for each class  \n",
        "1. Use $\\texttt{plot_surface}$ to plot the likelihood of each class.\n",
        "1. Use $\\texttt{contourf}$ to plot the likelihood of each class. \n",
        "\n",
        "You may find the code in the lecture notebook helpful.\n",
        " \n",
        "For the plots, use $\\texttt{cmap=cm.Reds}$ for class 1 and $\\texttt{cmap=cm.Blues}$ for class 2. Use $\\texttt{alpha=0.5}$ to overlay both plots together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjslmo-j83KH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZBa1Z5AfLc",
        "colab_type": "text"
      },
      "source": [
        "#Visualize the posterior\n",
        "Use the prior and the likelihood you've computed to obtain the posterior distribution for each class.\n",
        "\n",
        "Like in the case of the likelihood above, make same similar surface and contour plots for the posterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTQTLL0CAiij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-z8dLtbEkdi",
        "colab_type": "text"
      },
      "source": [
        "# Decision boundary\n",
        "1. Decision boundary can be obtained by $P(C_2|x)>P(C_1|x)$ in python. Use $\\texttt{contourf}$ to plot the decision boundary. Use $\\texttt{cmap=cm.Blues}$ and $\\texttt{alpha=0.5}$\n",
        "1. Also overlay the scatter plot of train data points from the 2 classes on the same plot. Use red color for class 1 and blue color for class 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GPzpqy2Dy_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBtAykz2FihL",
        "colab_type": "text"
      },
      "source": [
        "# Test Data\n",
        "Now let's use our trained model to classify test data points\n",
        "\n",
        "1. $\\texttt{test_data}$ contains the $x1,x2$ features of different data points\n",
        "1. $\\texttt{test_label}$ contains the true class of the data points. 0 means class 1. 1 means class 2.  \n",
        "1. Classify the test points based on whichever class has higher posterior probability for each data point\n",
        "1. Use $\\texttt{classification_report}$ to test the classification performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbxiXB0bD6le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('https://raw.githubusercontent.com/shala2020/shala2020.github.io/master/Lecture_Materials/Assignments/MachineLearning/L3/test').to_numpy()\n",
        "test_data, test_label = test[:,:2], test[:,2]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}