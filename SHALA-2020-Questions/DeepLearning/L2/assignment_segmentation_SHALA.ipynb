{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment segmentation_SHALA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFk-xL0nm_L8",
        "colab_type": "text"
      },
      "source": [
        "#Download CamVid Dataset\n",
        "\n",
        "Code in below cell downloads subset of CamVid dataset with 12 classes. Run the cell and download the data. Class names(12 in number) and 12 distinct RGB values for different colours is also given.\n",
        "\n",
        "- Print total number of train, val and test images available in dataset\n",
        "- Visualize any random image and corrosponding mask with the use of CLASS_NAMES and CLASS_COLORS\n",
        "- All the images are of same size. Print size of image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kUcGkX1fI3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = './data/CamVid/'\n",
        "\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print('Loading data...')\n",
        "    os.system('git clone https://github.com/alexgkendall/SegNet-Tutorial ./data')\n",
        "    print('Done!')\n",
        "    \n",
        "CLASS_NAMES = ['sky', 'building', 'pole', 'road', 'pavement',\n",
        "               'tree', 'signsymbol', 'fence', 'car',\n",
        "               'pedestrian', 'bicyclist', 'unlabelled']\n",
        "\n",
        "CLASS_COLORS = [(128, 128, 128), (128, 0, 0), (192, 192, 128), (128, 64, 128), (0, 0, 192),\n",
        "                (128, 128, 0), (192, 128, 128), (64, 64, 128), (64, 0, 128),\n",
        "                (64, 64, 0), (0, 128, 192), (0, 0, 0)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bOlSLc9on9g",
        "colab_type": "text"
      },
      "source": [
        "#DataLoader\n",
        "We are going to use code shared in [this](https://yann-leguilly.gitlab.io/post/2019-12-14-tensorflow-tfdata-segmentation/) blog post. In the blog, implementation of UNet for ADE20K dataset is given. \n",
        "- Using code in this blog, implement dataloader for CamVid dataset. Read tensorflow documentation for better understanding. (Do not resize images in dataset.)\n",
        "- Vizualize the data sample outputted by implemented dataloader for sanity check of your dataloader implentation. (Code is given in blog)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtCoFc_ntkWm",
        "colab_type": "text"
      },
      "source": [
        "#UNet Model\n",
        "- Copy the implementation of UNet from blog and train the model.\n",
        "- You will get an error if you have not resized images in Input layer. In lecture, we have seen that Fully Convolutional Networks can take any shape of image as input. Why are we getting an error?\n",
        "- In order to train UNet, you need to resize input images. Resize input images to closest possible change in size and train UNet using cross entropy loss for 10 epochs.\n",
        "- Vizualize the prediction for few images (Use code given in blog)\n",
        "- Most probably, you won't get pixel-wise accuracy more than 50%. There is a bug (design bug) in implementation, try to rectify it. (Hint: UNet paper proposed architecture for binary segmentation.)\n",
        "- [This project report](http://cs230.stanford.edu/files_winter_2018/projects/6937642.pdf) shows some modifications to original UNet paper. Implement it and retrain the model. Does it improve train and validation accuracy?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxkILmLyB2xr",
        "colab_type": "text"
      },
      "source": [
        "#Loss Function\n",
        "- As discussed in class, generally cross entropy loss is not used for training segmentation networks. [This paper](https://arxiv.org/pdf/1707.03237.pdf) proposes varient of Dice Loss, Generalized Dice Loss (GDL). [This](https://gitmemory.com/issue/keras-team/keras/9395/464445431) can help you to get started with implemetation of GDL. \n",
        "- Implement the GDL and train using it as a loss function.\n",
        "- Use combination of Dice and cross entropy loss.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvPK3u6BGBG8",
        "colab_type": "text"
      },
      "source": [
        "#Transfer learning\n",
        "- Implement ResNet-UNet model. You can take help from this post [MobileNet UNet](https://www.tensorflow.org/tutorials/images/segmentation)."
      ]
    }
  ]
}